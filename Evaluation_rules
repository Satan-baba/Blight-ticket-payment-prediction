Evaluation and rules

Your predictions will be given as the probability that the corresponding blight ticket will be paid on time.

The evaluation metric for this is the Area Under the ROC Curve (AUC).

Create a function that trains a model to predict blight ticket compliance in Detroit using train.csv. Using this model, return a series of length 61001 with the data being the probability that each corresponding ticket from test.csv will be paid, and the index being the ticket_id.

Example:

ticket_id
   284932    0.531842
   285362    0.401958
   285361    0.105928
   285338    0.018572
             ...
   376499    0.208567
   376500    0.818759
   369851    0.018528
   Name: compliance, dtype: float32

Rules

    Print out your result to see whether there is anything weird (e.g., all probabilities are the same).

    Generally the total runtime should be less than 10 mins. You should NOT use Neural Network related classifiers (e.g., MLPClassifier) in this question.

    Try to avoid global variables. If you have other functions besides blight_model, you should move those functions inside the scope of blight_model.
